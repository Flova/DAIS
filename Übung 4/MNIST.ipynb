{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A learning example from scikit learn\n",
    "\n",
    "# Now, we use data from the openml DB -> https://www.openml.org/d/554 (<- the number is the DB id)\n",
    "# We stay with the notation X and y\n",
    "\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X = X / 255. # We do some normalization here, because the pixels of the images have gray values \\in [0;255]\n",
    "\n",
    "# new school way to split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"hidden_layer_sizes\": (200, 100),\n",
    "    \"activation\": 'relu',\n",
    "    \"solver\": 'adam',\n",
    "    \"batch_size\": \"auto\",\n",
    "    \"learning_rate\": 'constant', \n",
    "    \"learning_rate_init\": 0.001,\n",
    "    \"max_iter\": 200,\n",
    "    \"shuffle\": True, \n",
    "    \"random_state\": 42, \n",
    "    \"tol\": 0.0001, \n",
    "    \"verbose\": 1, \n",
    "    \"early_stopping\": True,\n",
    "    \"validation_fraction\": 0.2, \n",
    "    \"n_iter_no_change\": 10,\n",
    "}\n",
    "\n",
    "mlp = MLPClassifier(**params) # design your network\n",
    "\n",
    "# Yes, it is still that easy to train a network\n",
    "mlp.fit(X_train, y_train)\n",
    "print(\"Training set score: %f\" % mlp.score(X_train, y_train))\n",
    "print(\"Test set score: %f\" % mlp.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# Do not change this part; It is a nice visualization of your weights (mlp.coefs). Do they change when varying your parameter? \n",
    "fig, axes = plt.subplots(4, 4)\n",
    "# use global min / max to ensure all weights are shown on the same scale\n",
    "vmin, vmax = mlp.coefs_[0].min(), mlp.coefs_[0].max()\n",
    "for coef, ax in zip(mlp.coefs_[0].T, axes.ravel()):\n",
    "    ax.matshow(coef.reshape(28, 28), cmap=plt.cm.gray, vmin=.5 * vmin,\n",
    "               vmax=.5 * vmax)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}